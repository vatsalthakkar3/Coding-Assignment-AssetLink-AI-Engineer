{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 376,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "import datetime\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "# from langchain.agents import create_sql_agent\n",
    "from langchain.agents.agent_toolkits import SQLDatabaseToolkit\n",
    "from langchain.sql_database import SQLDatabase\n",
    "from langchain.tools import tool\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.tools.render import format_tool_to_openai_function\n",
    "from langchain.agents.output_parsers import OpenAIFunctionsAgentOutputParser\n",
    "from langchain.prompts import MessagesPlaceholder\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.agents import AgentExecutor\n",
    "from langchain.schema.runnable import RunnablePassthrough\n",
    "from langchain_community.agent_toolkits.sql.prompt import (\n",
    "    SQL_FUNCTIONS_SUFFIX,\n",
    "    SQL_PREFIX,\n",
    ")\n",
    "from langchain.agents.format_scratchpad import format_to_openai_functions\n",
    "from dotenv import load_dotenv\n",
    "from langchain.agents import create_sql_agent\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file_path = \"../Data/AdvizorPro_Person.csv\"\n",
    "database_file_path = \"../database/test.db\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/mt/23v752753ggb8fbdcw2xjcn40000gn/T/ipykernel_43590/3293186784.py:2: DtypeWarning: Columns (18,64) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(csv_file_path).dropna(axis=1, how='all')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 378,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "engine = create_engine(f'sqlite:///{database_file_path}')\n",
    "df = pd.read_csv(csv_file_path).dropna(axis=1, how='all')\n",
    "df.to_sql(\n",
    "    'Person_Details',\n",
    "    con=engine,\n",
    "    if_exists='replace',\n",
    "    index=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [],
   "source": [
    "MSSQL_AGENT_PREFIX = \"\"\"\n",
    "You are an agent designed to interact with a SQL database which contains personal data of brokers.\n",
    "\n",
    "## Database Schema:\n",
    "- The database has a column CRD which is the primary key.\n",
    "- The table contains a LinkedIn column from which you can fetch the LinkedIn profile link of any particular person to get their details using the LinkedIn tool.\n",
    "\n",
    "## LinkedIn Tool Capabilities:\n",
    "- Using the LinkedIn tool, you can get information about the person such as their current job, company, location, headline, summary, positions, education, skills, projects, etc.\n",
    "\n",
    "## Instructions:\n",
    "\n",
    "### Query Creation and Execution:\n",
    "- First get all the columns names from the table and find the most relevent column names which can be used to get the required information.\n",
    "- Given an input question, create a syntactically correct {dialect} query to run.\n",
    "- Look at the results of the query and return the answer.\n",
    "- Unless the user specifies a specific number of examples they wish to obtain, always limit your query to at most {top_k} results.\n",
    "- You can order the results by a relevant column to return the most interesting examples in the database.\n",
    "\n",
    "### Validation and Error Handling:\n",
    "- Double-check your query before executing it.\n",
    "- If you get an error while executing a query, rewrite the query and try again.\n",
    "- Do not make any DML statements (INSERT, UPDATE, DELETE, DROP, etc.) to the database.\n",
    "- Do not make up an answer or use prior knowledge, only use the results of the calculations you have done.\n",
    "\n",
    "### Response Formatting:\n",
    "- Your response should be in Markdown.\n",
    "- When running a SQL query in \"Action Input\", do not include the markdown backticks. Those are only for formatting the response, not for executing the command.\n",
    "\n",
    "### Explanation Section:\n",
    "- Always, as part of your final answer, explain how you got to the answer in a section that starts with: \"Explanation:\".\n",
    "\n",
    "## Tools:\n",
    "- Only use the below tools.\n",
    "- Only use the information returned by the below tools to construct your query and final answer.\n",
    "- Do not make up table names, only use the tables returned by any of the tools below.\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(temperature=0.3)\n",
    "db = SQLDatabase.from_uri(f'sqlite:///{database_file_path}')\n",
    "toolkit = SQLDatabaseToolkit(db=db, llm=llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatOpenAI(client=<class 'openai.api_resources.chat_completion.ChatCompletion'>, temperature=0.3, openai_api_key='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', openai_proxy='')"
      ]
     },
     "execution_count": 381,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the input schema\n",
    "class LinkedinInput(BaseModel):\n",
    "    query_url: str = Field(..., description=\"Linkedin URL of the person for whom you want to fetch data\")\n",
    "\n",
    "@tool(args_schema=LinkedinInput)\n",
    "def get_linkedin_profile_data(query_url: str) -> dict:\n",
    "    \"\"\"Fetch the linkedin profile data of a person using the linkedin-data-api\n",
    "    which will contain the persons information like his current job, company, location, headline, summary, positions, educations, skills, projects etc.\n",
    "    \"\"\"\n",
    "    url = \"https://linkedin-data-api.p.rapidapi.com/get-profile-data-by-url\"\n",
    "    \n",
    "    querystring = {\"url\": query_url}  # Replace with the actual profile URL\n",
    "\n",
    "    headers = {\n",
    "    'x-rapidapi-key': os.getenv('RAPID_API_KEY'),\n",
    "    'x-rapidapi-host': \"linkedin-data-api.p.rapidapi.com\"\n",
    "}\n",
    "\n",
    "    try:\n",
    "        response = requests.get(url, headers=headers, params=querystring)\n",
    "        response.raise_for_status()  # Raises HTTPError for bad responses (4xx or 5xx)\n",
    "        profile_data = response.json()\n",
    "        \n",
    "        extracted_data = {\n",
    "            \"username\": profile_data.get(\"username\"),\n",
    "            \"full_name\": f\"{profile_data.get('firstName', '')} {profile_data.get('lastName', '')}\",\n",
    "            \"is_open_to_work\": profile_data.get(\"isOpenToWork\"),\n",
    "            \"is_hiring\": profile_data.get(\"isHiring\"),\n",
    "            \"headline\": profile_data.get(\"headline\"),\n",
    "            \"summary\": profile_data.get(\"summary\"),\n",
    "            \"location\": profile_data.get(\"geo\", {}).get(\"full\"),\n",
    "            \"skills\": profile_data.get(\"skills\", []),\n",
    "            \"education\": [\n",
    "                {\n",
    "                    \"institution\": edu.get(\"institutionName\"),\n",
    "                    \"degree\": edu.get(\"degreeName\"),\n",
    "                    \"field_of_study\": edu.get(\"fieldOfStudy\"),\n",
    "                    \"start_date\": edu.get(\"timePeriod\", {}).get(\"startDate\", {}).get(\"year\"),\n",
    "                    \"end_date\": edu.get(\"timePeriod\", {}).get(\"endDate\", {}).get(\"year\"),\n",
    "                } for edu in profile_data.get(\"educations\", [])\n",
    "            ],\n",
    "            \"positions\": [\n",
    "                {\n",
    "                    \"title\": pos.get(\"title\"),\n",
    "                    \"company\": pos.get(\"companyName\"),\n",
    "                    \"location\": pos.get(\"geoLocationName\"),\n",
    "                    \"start_date\": pos.get(\"timePeriod\", {}).get(\"startDate\", {}).get(\"year\"),\n",
    "                    \"end_date\": pos.get(\"timePeriod\", {}).get(\"endDate\", {}).get(\"year\"),\n",
    "                    \"description\": pos.get(\"description\"),\n",
    "                } for pos in profile_data.get(\"position\", [])\n",
    "            ],\n",
    "            \"projects\": [\n",
    "                {\n",
    "                    \"title\": proj.get(\"title\"),\n",
    "                    \"description\": proj.get(\"description\"),\n",
    "                    \"start_date\": proj.get(\"timePeriod\", {}).get(\"startDate\", {}).get(\"year\"),\n",
    "                    \"end_date\": proj.get(\"timePeriod\", {}).get(\"endDate\", {}).get(\"year\"),\n",
    "                } for proj in profile_data.get(\"projects\", {}).get(\"items\", [])\n",
    "            ]\n",
    "        }\n",
    "        \n",
    "        return extracted_data\n",
    "\n",
    "    except requests.exceptions.HTTPError as http_err:\n",
    "        print(f\"HTTP error occurred: {http_err}\")\n",
    "    except requests.exceptions.ConnectionError as conn_err:\n",
    "        print(f\"Connection error occurred: {conn_err}\")\n",
    "    except requests.exceptions.Timeout as timeout_err:\n",
    "        print(f\"Timeout error occurred: {timeout_err}\")\n",
    "    except requests.exceptions.RequestException as req_err:\n",
    "        print(f\"An error occurred: {req_err}\")\n",
    "    except Exception as err:\n",
    "        print(f\"An unexpected error occurred: {err}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tool CRD Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'selenium'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[383], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mselenium\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m webdriver\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mselenium\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mwebdriver\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcommon\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mby\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m By\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mselenium\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mwebdriver\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msupport\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mwait\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m WebDriverWait\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'selenium'"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.wait import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "from bs4 import BeautifulSoup\n",
    "# Define the input schema\n",
    "class BrockerCheckInput(BaseModel):\n",
    "    crd: str = Field(..., description=\"CRD Number of the person for whom you want to fetch data\")\n",
    "\n",
    "@tool(args_schema=BrockerCheckInput)\n",
    "def get_brokercheck_profile_data(crd: str) -> dict:\n",
    "    \"\"\"Fetch the BrokerCheck profile for given person.\"\"\"\n",
    "    link = f\"https://brokercheck.finra.org/individual/summary/{crd}\"\n",
    "    options = webdriver.ChromeOptions()\n",
    "    options.add_experimental_option('excludeSwitches', ['enable-logging'])\n",
    "    driver = webdriver.Chrome(options=options)\n",
    "\n",
    "    response = []\n",
    "\n",
    "    timeout = False\n",
    "    driver.get(link)\n",
    "\n",
    "    try:\n",
    "        element = WebDriverWait(driver, 2).until(\n",
    "            EC.presence_of_element_located((By.XPATH, \"/html/body/bc-root/div/bc-individual-container-page/bc-individual-detail-page/div[2]/investor-tools-individual-summary-template/div/div[1]/div[1]/div/investor-tools-big-name/div[1]/span[1]\"))\n",
    "        )\n",
    "    except TimeoutException:\n",
    "        timeout = True\n",
    "    finally:\n",
    "        if not timeout:\n",
    "            response=(driver.page_source)\n",
    "        else:\n",
    "            response=(int(link.rsplit('/', 1)[1]),\"IA\")\n",
    "            timeout = False\n",
    "        \n",
    "\n",
    "    driver.quit()\n",
    "    \n",
    "    scraped_data_partial = {}\n",
    "    if type(response) == tuple:\n",
    "        scraped_data_partial[\"Broker CRD\"] = response[0]\n",
    "        scraped_data_partial[\"Is a Broker\"] = \"null\"\n",
    "        scraped_data_partial[\"Is an Investment Adviser\"] = True\n",
    "    else:\n",
    "        soup = BeautifulSoup(response, features=\"html.parser\")\n",
    "        scraped_data_partial[\"name\"] = soup.find(\n",
    "            \"span\", {\"class\": \"text-lg sm:text-sm font-semibold\"}\n",
    "        )\n",
    "        scraped_data_partial[\"status\"] = soup.find_all(\n",
    "            \"span\", {\"class\": \"text-gray-80 text-xs font-medium\"}\n",
    "        )\n",
    "        scraped_data_partial[\"crd\"] = soup.find(\n",
    "            \"div\",\n",
    "            {\n",
    "                \"class\": \"text-gray-85 text-left font-semibold mt-2 text-sm ng-star-inserted\"\n",
    "            },\n",
    "        )\n",
    "        scraped_data_partial[\"firm\"] = soup.find(\n",
    "            \"div\", {\"class\": \"flex flex-col text-sm\"}\n",
    "        )\n",
    "        scraped_data_partial[\"background\"] = soup.find_all(\n",
    "            \"div\", {\"class\": \"flex-1 flex flex-col justify-center\"}\n",
    "        )\n",
    "\n",
    "    scrape = scraped_data_partial\n",
    "\n",
    "    if len(scrape) > 3:\n",
    "        clean_data = {}\n",
    "        clean_data[\"Broker Name\"] = scrape[\"name\"].string.strip()\n",
    "\n",
    "        raw_status = scrape[\"status\"]\n",
    "\n",
    "        if len(raw_status) == 1:\n",
    "            if scrape[\"status\"][0].find(\"span\").string == \"Broker\":\n",
    "                clean_data[\"Is a Broker\"] = True\n",
    "            else:\n",
    "                clean_data[\"Is a Broker\"] = False\n",
    "\n",
    "            clean_data[\"Is an Investment Adviser\"] = False\n",
    "        else:\n",
    "            if raw_status[1].find(\"span\").string == \"Broker\":\n",
    "                clean_data[\"Is a Broker\"] = True\n",
    "            else:\n",
    "                clean_data[\"Is a Broker\"] = False\n",
    "\n",
    "            if (\n",
    "                raw_status[0]\n",
    "                .find(\"span\", {\"title\": \"Investment Adviser\"})\n",
    "                .string.strip()\n",
    "                == \"Investment Adviser\"\n",
    "            ):\n",
    "                clean_data[\"Is an Investment Adviser\"] = True\n",
    "            else:\n",
    "                clean_data[\"Is an Investment Adviser\"] = False\n",
    "\n",
    "        clean_data[\"Broker CRD\"] = int(scrape[\"crd\"].find(\"span\").next_sibling.string)\n",
    "\n",
    "        if scrape[\"firm\"]:\n",
    "            clean_data[\"Firm Name\"] = scrape[\"firm\"].find(\"span\").string\n",
    "            clean_data[\"Firm CRD\"] = int(\n",
    "                scrape[\"firm\"]\n",
    "                .find(\"span\")\n",
    "                .next_sibling.find(\"span\")\n",
    "                .next_sibling.string\n",
    "            )\n",
    "\n",
    "            rawAddress = scrape[\"firm\"].find(\"investor-tools-address\")\n",
    "\n",
    "            rawStreetAddress = rawAddress.next_element\n",
    "\n",
    "            for x in range(3):\n",
    "                rawStreetAddress = rawStreetAddress.next_element\n",
    "\n",
    "            clean_data[\"Firm Street\"] = rawStreetAddress.strip()\n",
    "\n",
    "            rawCityStateZip = rawAddress.find(\"br\")\n",
    "\n",
    "            # for x in range(4):\n",
    "            #     rawCityStateZip = rawCityStateZip.next_element\n",
    "\n",
    "            #     rawCityStateZip = rawCityStateZip.strip()\n",
    "\n",
    "            #     rawStateZip = rawCityStateZip.split(\" \", 1)[1].split(\" \", 1)\n",
    "\n",
    "            # clean_data[\"Firm State\"] = rawStateZip[0]\n",
    "\n",
    "            # clean_data[\"Firm Zip\"] = rawStateZip[1]\n",
    "        else:\n",
    "            clean_data[\"Firm Name\"] = \"none\"\n",
    "            clean_data[\"Firm CRD\"] = \"none\"\n",
    "            clean_data[\"Firm Street\"] = \"none\"\n",
    "            clean_data[\"Firm State\"] = \"none\"\n",
    "            clean_data[\"Firm Zip\"] = \"none\"\n",
    "\n",
    "        clean_data[\"Number of Disclosures\"] = int(\n",
    "            scrape[\"background\"][0]\n",
    "            .find(\n",
    "                \"span\",\n",
    "                {\"class\": \"sm:text-lg sm:font-semibold text-3xl ng-star-inserted\"},\n",
    "            )\n",
    "            .string.strip()\n",
    "        )\n",
    "\n",
    "        rawYearsFirms = scrape[\"background\"][1].find_all(\n",
    "            \"span\", {\"class\": \"sm:text-lg sm:font-semibold text-3xl ng-star-inserted\"}\n",
    "        )\n",
    "\n",
    "        if len(rawYearsFirms) == 2:\n",
    "            clean_data[\"Years of Experience\"] = int(rawYearsFirms[0].string.strip())\n",
    "            clean_data[\"Number of Firms\"] = rawYearsFirms[1].string.strip()\n",
    "        else:\n",
    "            clean_data[\"Years of Experience\"] = int(rawYearsFirms[0].string.strip())\n",
    "            clean_data[\"Number of Firms\"] = (\n",
    "                scrape[\"background\"][1]\n",
    "                .find(\n",
    "                    \"span\",\n",
    "                    {\"class\": \"sm:text-lg sm:font-semibold text-xl ng-star-inserted\"},\n",
    "                )\n",
    "                .string.strip()\n",
    "            )\n",
    "\n",
    "        scraped_data_clean = clean_data\n",
    "    else:\n",
    "        scraped_data_clean = scrape\n",
    "\n",
    "    return scraped_data_clean\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Broker Name': 'DOUGLAS  GAINES',\n",
       " 'Is a Broker': True,\n",
       " 'Is an Investment Adviser': True,\n",
       " 'Broker CRD': 1000059,\n",
       " 'Firm Name': 'STIFEL, NICOLAUS & COMPANY, INCORPORATED',\n",
       " 'Firm CRD': 793,\n",
       " 'Firm Street': '10400 NE 4TH STREET, SUITE 2000',\n",
       " 'Firm State': 'WA',\n",
       " 'Firm Zip': '98004',\n",
       " 'Number of Disclosures': 0,\n",
       " 'Years of Experience': 42,\n",
       " 'Number of Firms': '4'}"
      ]
     },
     "execution_count": 384,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_brokercheck_profile_data(\"1000072\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = toolkit.get_tools() + [get_linkedin_profile_data , get_brokercheck_profile_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions = [format_tool_to_openai_function(f) for f in tools]\n",
    "# model = ChatOpenAI(temperature=0).bind(functions=functions)\n",
    "# prompt = ChatPromptTemplate.from_messages([\n",
    "#     (\"system\", MSSQL_AGENT_PREFIX),\n",
    "#     MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "#     (\"user\", \"{input}\"),\n",
    "#     MessagesPlaceholder(variable_name=\"agent_scratchpad\")\n",
    "# ])\n",
    "# if \"top_k\" in prompt.input_variables:\n",
    "#             prompt = prompt.partial(top_k=str(10))\n",
    "# if \"dialect\" in prompt.input_variables:\n",
    "#     prompt = prompt.partial(dialect=toolkit.dialect)\n",
    "# agent_chain = RunnablePassthrough.assign(\n",
    "#     agent_scratchpad= lambda x: format_to_openai_functions(x[\"intermediate_steps\"])\n",
    "# ) | prompt | model | OpenAIFunctionsAgentOutputParser()\n",
    "# memory = ConversationBufferMemory(return_messages=True,memory_key=\"chat_history\")\n",
    "# agent_executor = AgentExecutor(agent=agent_chain, tools=tools, verbose=False, memory=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(agent_executor.invoke({\"input\": \"find the similar persons to the crn 1000059\"}).get('output'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# agent_executor.invoke({\"input\": \"why do you think they are similar\"}).get('output')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import panel as pn  # GUI\n",
    "pn.extension()\n",
    "import panel as pn\n",
    "import param\n",
    "\n",
    "class cbfs(param.Parameterized):\n",
    "    \n",
    "    def __init__(self, tools, **params):\n",
    "        super(cbfs, self).__init__( **params)\n",
    "        self.panels = []\n",
    "        self.functions = [format_tool_to_openai_function(f) for f in tools]\n",
    "        self.model = llm.bind(functions=self.functions)\n",
    "        self.memory = ConversationBufferMemory(return_messages=True,memory_key=\"chat_history\")\n",
    "        self.prompt =  ChatPromptTemplate.from_messages([\n",
    "            (\"system\", MSSQL_AGENT_PREFIX),\n",
    "            MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "            (\"user\", \"{input}\"),\n",
    "            MessagesPlaceholder(variable_name=\"agent_scratchpad\")\n",
    "        ])\n",
    "        if \"top_k\" in self.prompt.input_variables:\n",
    "            self.prompt = self.prompt.partial(top_k=str(10))\n",
    "        if \"dialect\" in self.prompt.input_variables:\n",
    "            self.prompt = self.prompt.partial(dialect=toolkit.dialect)\n",
    "        self.chain = RunnablePassthrough.assign(\n",
    "            agent_scratchpad= lambda x: format_to_openai_functions(x[\"intermediate_steps\"])\n",
    "        ) | self.prompt | self.model | OpenAIFunctionsAgentOutputParser()\n",
    "        self.qa = AgentExecutor(agent=self.chain, tools=tools, verbose=False, memory=self.memory)\n",
    "        \n",
    "    \n",
    "    def convchain(self, query):\n",
    "        if not query:\n",
    "            return\n",
    "        inp.value = ''\n",
    "        result = self.qa.invoke({\"input\": query})\n",
    "        self.answer = result['output'] \n",
    "        self.panels.extend([\n",
    "            pn.Row('User:', pn.pane.Markdown(query, width=450)),\n",
    "            pn.Row('ChatBot:', pn.pane.Markdown(self.answer, width=450, styles={'background-color': '#F3F3F3'}))\n",
    "        ])\n",
    "        return pn.WidgetBox(*self.panels, scroll=True)\n",
    "\n",
    "\n",
    "    def clr_history(self,count=0):\n",
    "        self.chat_history = []\n",
    "        return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cb = cbfs(tools)\n",
    "\n",
    "inp = pn.widgets.TextInput( placeholder='Enter text here…')\n",
    "\n",
    "conversation = pn.bind(cb.convchain, inp) \n",
    "\n",
    "tab1 = pn.Column(\n",
    "    pn.Row(inp),\n",
    "    pn.layout.Divider(),\n",
    "    pn.panel(conversation,  loading_indicator=True, height=2000),\n",
    "    pn.layout.Divider(),\n",
    ")\n",
    "\n",
    "dashboard = pn.Column(\n",
    "    pn.Row(pn.pane.Markdown('# QnA_Bot')),\n",
    "    pn.Tabs(('Conversation', tab1))\n",
    ")\n",
    "dashboard\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
