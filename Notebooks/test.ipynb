{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from json import load\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain.tools import tool\n",
    "import requests\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "class LinkedinInput(BaseModel):\n",
    "    query_url: str = Field(\n",
    "        ..., description=\"Linkedin URL of the person for whom you want to fetch data\"\n",
    "    )\n",
    "\n",
    "\n",
    "@tool(args_schema=LinkedinInput)\n",
    "def get_linkedin_profile_data(query_url: str) -> dict:\n",
    "    \"\"\"Fetch the linkedin profile data of a person using the linkedin profile URL mentioned in the Linkedin Column of in the database.\n",
    "    Output will contain the persons information like his current job, company, location, headline, summary, positions, educations, skills, projects etc.\n",
    "    \"\"\"\n",
    "    url = \"https://linkedin-data-api.p.rapidapi.com/get-profile-data-by-url\"\n",
    "\n",
    "    querystring = {\"url\": query_url}  # Replace with the actual profile URL\n",
    "\n",
    "    headers = {\n",
    "        \"x-rapidapi-key\": os.getenv(\"RAPID_API_KEY\"),\n",
    "        \"x-rapidapi-host\": \"linkedin-data-api.p.rapidapi.com\",\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        response = requests.get(url, headers=headers, params=querystring)\n",
    "        response.raise_for_status()  # Raises HTTPError for bad responses (4xx or 5xx)\n",
    "        profile_data = response.json()\n",
    "\n",
    "        extracted_data = {\n",
    "            \"username\": profile_data.get(\"username\"),\n",
    "            \"full_name\": f\"{profile_data.get('firstName', '')} {profile_data.get('lastName', '')}\",\n",
    "            \"is_open_to_work\": profile_data.get(\"isOpenToWork\"),\n",
    "            \"is_hiring\": profile_data.get(\"isHiring\"),\n",
    "            \"headline\": profile_data.get(\"headline\"),\n",
    "            \"summary\": profile_data.get(\"summary\"),\n",
    "            \"location\": profile_data.get(\"geo\", {}).get(\"full\"),\n",
    "            \"skills\": profile_data.get(\"skills\", []),\n",
    "            \"education\": [\n",
    "                {\n",
    "                    \"institution\": edu.get(\"institutionName\"),\n",
    "                    \"degree\": edu.get(\"degreeName\"),\n",
    "                    \"field_of_study\": edu.get(\"fieldOfStudy\"),\n",
    "                    \"start_date\": edu.get(\"timePeriod\", {})\n",
    "                    .get(\"startDate\", {})\n",
    "                    .get(\"year\"),\n",
    "                    \"end_date\": edu.get(\"timePeriod\", {})\n",
    "                    .get(\"endDate\", {})\n",
    "                    .get(\"year\"),\n",
    "                }\n",
    "                for edu in profile_data.get(\"educations\", [])\n",
    "            ],\n",
    "            \"positions\": [\n",
    "                {\n",
    "                    \"title\": pos.get(\"title\"),\n",
    "                    \"company\": pos.get(\"companyName\"),\n",
    "                    \"location\": pos.get(\"geoLocationName\"),\n",
    "                    \"start_date\": pos.get(\"timePeriod\", {})\n",
    "                    .get(\"startDate\", {})\n",
    "                    .get(\"year\"),\n",
    "                    \"end_date\": pos.get(\"timePeriod\", {})\n",
    "                    .get(\"endDate\", {})\n",
    "                    .get(\"year\"),\n",
    "                    \"description\": pos.get(\"description\"),\n",
    "                }\n",
    "                for pos in profile_data.get(\"position\", [])\n",
    "            ],\n",
    "            \"projects\": [\n",
    "                {\n",
    "                    \"title\": proj.get(\"title\"),\n",
    "                    \"description\": proj.get(\"description\"),\n",
    "                    \"start_date\": proj.get(\"timePeriod\", {})\n",
    "                    .get(\"startDate\", {})\n",
    "                    .get(\"year\"),\n",
    "                    \"end_date\": proj.get(\"timePeriod\", {})\n",
    "                    .get(\"endDate\", {})\n",
    "                    .get(\"year\"),\n",
    "                }\n",
    "                for proj in profile_data.get(\"projects\", {}).get(\"items\", [])\n",
    "            ],\n",
    "        }\n",
    "\n",
    "        return extracted_data\n",
    "\n",
    "    except requests.exceptions.HTTPError as http_err:\n",
    "        print(f\"HTTP error occurred: {http_err}\")\n",
    "    except requests.exceptions.ConnectionError as conn_err:\n",
    "        print(f\"Connection error occurred: {conn_err}\")\n",
    "    except requests.exceptions.Timeout as timeout_err:\n",
    "        print(f\"Timeout error occurred: {timeout_err}\")\n",
    "    except requests.exceptions.RequestException as req_err:\n",
    "        print(f\"An error occurred: {req_err}\")\n",
    "    except Exception as err:\n",
    "        print(f\"An unexpected error occurred: {err}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'username': 'vatsal-thakkar-880320161',\n",
       " 'full_name': 'Vatsal Thakkar',\n",
       " 'is_open_to_work': True,\n",
       " 'is_hiring': False,\n",
       " 'headline': 'Masters in Computer Science | Passionate about Deep Learning & Generative Models | Computer Vision | LLMs | Multimodal Representation Learning',\n",
       " 'summary': \"I am currently pursuing a Master's Degree in Computer Science from The University of Georgia. I am passionate about Generative Deep Learning Models, including GPT, BERT, Stable Diffusion, and GANs, as well as Multimodal Representation Learning.\\n\\nðŸ’¼ Professional Experience:\\nAs a Research Assistant at The Hoarfrost Lab, I'm currently contributing to a cutting-edge project that involves integrating textual and DNA sequence data using the Multimodal Language Model.\\n\\nIn my most recent role as an LLM and AI Engineer at ColomboAI, I led the implementation of the RAG (Retrieval Augmented Generation) Pipeline. Along with this, I designed and executed a Mixture-of-Experts (MoE) methodology. I also engineered effective prompts while utilizing advanced prompt engineering strategies.\\n\\nDuring my time as a Junior Software Engineer at ECPL Edtech, India, I developed predictive analytics models, data visualization dashboards, and scalable software systems using Machine Learning and Flask Web Framework.\\n\\nðŸš€ Projects:\\nI'm currently working on a fascinating project involving text-to-image generative Diffusion Models, where I'm exploring the explainability of images generated by Stable Diffusion from textual prompts.\\n\\nðŸ§  Skills:\\nProgramming Languages: Proficient in Python, JavaScript, and Java.\\nAI Frameworks: Experienced with PyTorch and TensorFlow.\\nWeb Development: Skilled in Flask, Django, React.js, and Node.js.\\nDatabase Management: Proficient in MySQL and MongoDB.\\nTools: Git, Docker, NLP techniques, and LLMs.\\n\\n#DeepLearning #NLP #GenerativeAI #MultimodalAI #MachineLearning #ComputerVision\",\n",
       " 'location': 'Sunnyvale, California, United States',\n",
       " 'skills': [{'name': 'Google Cloud Platform (GCP)',\n",
       "   'passedSkillAssessment': False},\n",
       "  {'name': 'Deep Learning', 'passedSkillAssessment': False},\n",
       "  {'name': 'Natural Language Processing (NLP)',\n",
       "   'passedSkillAssessment': False},\n",
       "  {'name': 'Multimodal AI', 'passedSkillAssessment': False},\n",
       "  {'name': 'LangChain', 'passedSkillAssessment': False},\n",
       "  {'name': 'PyTorch', 'passedSkillAssessment': False},\n",
       "  {'name': 'Diffusers', 'passedSkillAssessment': False},\n",
       "  {'name': 'Prompt Engineering', 'passedSkillAssessment': False},\n",
       "  {'name': 'GPT-3', 'passedSkillAssessment': False},\n",
       "  {'name': 'Machine Learning', 'passedSkillAssessment': False},\n",
       "  {'name': 'Large Language Models (LLM)', 'passedSkillAssessment': False},\n",
       "  {'name': 'Computer Vision', 'passedSkillAssessment': False},\n",
       "  {'name': 'Machine Learning Algorithms', 'passedSkillAssessment': False},\n",
       "  {'name': 'Hugging Face', 'passedSkillAssessment': False},\n",
       "  {'name': 'BERT (Language Model)', 'passedSkillAssessment': False},\n",
       "  {'name': 'TensorFlow', 'passedSkillAssessment': False},\n",
       "  {'name': 'Python (Programming Language)', 'passedSkillAssessment': True},\n",
       "  {'name': 'Artificial Intelligence (AI)', 'passedSkillAssessment': False},\n",
       "  {'name': 'Oracle Database', 'passedSkillAssessment': False},\n",
       "  {'name': 'NumPy', 'passedSkillAssessment': False},\n",
       "  {'name': 'Scikit-Learn', 'passedSkillAssessment': False},\n",
       "  {'name': 'MySQL', 'passedSkillAssessment': False},\n",
       "  {'name': 'PostgreSQL', 'passedSkillAssessment': False},\n",
       "  {'name': 'MongoDB', 'passedSkillAssessment': False},\n",
       "  {'name': 'JavaScript', 'passedSkillAssessment': False},\n",
       "  {'name': 'DevOps', 'passedSkillAssessment': False},\n",
       "  {'name': 'Continuous Integration and Continuous Delivery (CI/CD)',\n",
       "   'passedSkillAssessment': False},\n",
       "  {'name': 'CUDA', 'passedSkillAssessment': False},\n",
       "  {'name': 'Java', 'passedSkillAssessment': True},\n",
       "  {'name': 'Git', 'passedSkillAssessment': False},\n",
       "  {'name': 'Django', 'passedSkillAssessment': False},\n",
       "  {'name': 'GitHub', 'passedSkillAssessment': False},\n",
       "  {'name': 'Flask', 'passedSkillAssessment': False},\n",
       "  {'name': 'Recommender Systems', 'passedSkillAssessment': False},\n",
       "  {'name': 'Gradle', 'passedSkillAssessment': False},\n",
       "  {'name': 'Data Science', 'passedSkillAssessment': False},\n",
       "  {'name': 'Linux', 'passedSkillAssessment': False},\n",
       "  {'name': 'SQL', 'passedSkillAssessment': False},\n",
       "  {'name': 'React.js', 'passedSkillAssessment': False},\n",
       "  {'name': 'Web Development', 'passedSkillAssessment': False},\n",
       "  {'name': 'Data Analysis', 'passedSkillAssessment': False},\n",
       "  {'name': 'Engineering', 'passedSkillAssessment': False},\n",
       "  {'name': 'Data Structures', 'passedSkillAssessment': False},\n",
       "  {'name': 'C++', 'passedSkillAssessment': True},\n",
       "  {'name': 'HTML', 'passedSkillAssessment': False},\n",
       "  {'name': 'Cascading Style Sheets (CSS)', 'passedSkillAssessment': True},\n",
       "  {'name': 'JavaServer Pages (JSP)', 'passedSkillAssessment': False},\n",
       "  {'name': 'C (Programming Language)', 'passedSkillAssessment': False},\n",
       "  {'name': 'Microsoft Excel', 'passedSkillAssessment': False},\n",
       "  {'name': 'Pianist', 'passedSkillAssessment': False}],\n",
       " 'education': [{'institution': None,\n",
       "   'degree': None,\n",
       "   'field_of_study': 'Computer Science',\n",
       "   'start_date': None,\n",
       "   'end_date': None},\n",
       "  {'institution': None,\n",
       "   'degree': None,\n",
       "   'field_of_study': 'Computer Engineering',\n",
       "   'start_date': None,\n",
       "   'end_date': None}],\n",
       " 'positions': [{'title': 'Research Assistant',\n",
       "   'company': 'The University of Georgia',\n",
       "   'location': None,\n",
       "   'start_date': None,\n",
       "   'end_date': None,\n",
       "   'description': 'â€¢\\tCollaborated on a pioneering research project focused on developing a Multimodal AI model to integrate textual and DNA sequence data.\\nâ€¢\\tGathered and meticulously processed large-scale DNA sequence functionality data, priming it for subsequent natural language processing.\\nâ€¢\\tEmployed advanced prompt engineering techniques to craft prompts for LLMs (GPT-3.5/4 and Llama-2), extracting meaningful textual descriptions from structured DNA data, and enabling seamless inter-modality communication.'},\n",
       "  {'title': 'Molecular Lab Student Assistant',\n",
       "   'company': 'The University of Georgia',\n",
       "   'location': None,\n",
       "   'start_date': None,\n",
       "   'end_date': None,\n",
       "   'description': 'â€¢ Performed data entry and analysis tasks, ensuring accuracy and reliability of molecular lab data.\\nâ€¢ Developed real-time interactive charts to visualize complex molecular data, aiding in data interpretation and decision-making processes.\\nâ€¢ Prepared PCR reagents following stringent laboratory guidelines, maintaining the highest standards of quality control and lab safety.\\nâ€¢ Utilized Python scripting to automate various tasks on the Opentron-OT2 platform,  resulting in a remarkable 20-30% increase in efficiency and a reduction in manual overhead.'},\n",
       "  {'title': 'Graduate Lab Assistant',\n",
       "   'company': 'University of Georgia - Franklin College of Arts and Sciences',\n",
       "   'location': None,\n",
       "   'start_date': None,\n",
       "   'end_date': None,\n",
       "   'description': 'â€¢\\tLed lab courses independently as the Graduate Lab Assistant, handling teaching and grading responsibilities in line with university policies.\\nâ€¢\\tProvided hands-on support to students during experiments, offering guidance on techniques and procedures.\\nâ€¢\\tAddressed student inquiries, and concerns, and provided constructive feedback on their performance.'},\n",
       "  {'title': 'LLM & AI Engineer',\n",
       "   'company': 'ColomboAI',\n",
       "   'location': None,\n",
       "   'start_date': None,\n",
       "   'end_date': None,\n",
       "   'description': 'â€¢\\tImplemented the RAG (Retrieval Augmented Generation) Pipeline to enhance response generation by combining Large Language Models with relevant search content, reducing hallucination in generated responses.\\nâ€¢\\tDesigned and implemented a Mixture-of-Experts (MoE) approach, allowing the LLM to dynamically select appropriate models based on user queries, leveraging the concept of chains and agents using a LangChain framework.\\nâ€¢\\tDeployed Generative Deep Learning models including diffusion models, on Google Cloud Platform endpoints, using Vertex AI and monitored their performance for optimization.\\nâ€¢\\tEngineered effective prompts by employing advanced prompt engineering strategies, optimizing  LLMâ€™s responses to user queries.\\nâ€¢\\tCollaborated with cross-functional teams to seamlessly integrate the Generative Engine Response Page into existing systems, ensuring compatibility and efficiency.'},\n",
       "  {'title': 'Junior Software Engineer',\n",
       "   'company': 'ECPL EdTech',\n",
       "   'location': None,\n",
       "   'start_date': None,\n",
       "   'end_date': None,\n",
       "   'description': 'â€¢\\tDeveloped a predictive analytics model, specifically tailored to analyze user performance on tests by incorporating diverse parameters, which led to a substantial 10% enhancement in the precision of personalized test preparation plans.\\nâ€¢\\tCreated intuitive and actionable dashboards by leveraging data visualization techniques and implementing REST APIs, enabling users to gain valuable insights for informed decision-making, resulting in a significant 25% reduction in data analysis time.\\nâ€¢\\tCollaborated with cross-functional teams to design scalable software systems, utilizing Machine Learning Algorithms, Flask Web Framework, and MySQL, and adhered to best software development practices such as version control and agile development methodologies.\\nâ€¢\\tDeveloped comprehensive test scripts and scenarios to thoroughly validate the functionality and performance of the software system.'},\n",
       "  {'title': 'Managing Director',\n",
       "   'company': 'Shree Narnarayan Enterprise',\n",
       "   'location': None,\n",
       "   'start_date': None,\n",
       "   'end_date': None,\n",
       "   'description': ''}],\n",
       " 'projects': [{'title': 'CharGPT with PerceiverAR Optimization',\n",
       "   'description': 'â€¢\\tDesigned and developed a character-level miniGPT model from scratch, encompassing essential components including self-attention, and cross-attention, resulting in a streamlined 1GB model size.\\nâ€¢\\tImplemented techniques like PerceiverAR to enhance model efficiency, strategically reducing sequence length by 50% and compute time by 75%, demonstrating exceptional proficiency in leveraging advanced methodologies for optimal performance and resource utilization.',\n",
       "   'start_date': None,\n",
       "   'end_date': None},\n",
       "  {'title': 'Decoding the Absence: Negative Prompts in Stable Diffusion (Research Project)',\n",
       "   'description': 'â€¢\\tImplemented a novel prompt optimization technique to approximate a fused prompt, able to generate semantically similar images as a result of combining positive and negative prompts, aiming to understand the semantic transformations induced by negative prompts.\\nâ€¢\\tInvestigated the role of positive and negative prompts in guiding the image generation process within text-to-image generative diffusion models, highlighting their pivotal influence on model behavior.',\n",
       "   'start_date': None,\n",
       "   'end_date': None},\n",
       "  {'title': 'The Unspoken Context in Stable Diffusion (Research Project)',\n",
       "   'description': \"â€¢\\tDeveloped ContextNet as a solution to generate context-only text embeddings based on prompts to visualize unspoken context in generated images using Stable Diffusion. \\nâ€¢\\tExplored and evaluated the potential of incorporating prompt-based learning techniques in text-to-image generative diffusion models, enhancing the model's ability to generate images based on textual prompts.\\nâ€¢\\tConducted fine-tuning and training of a stable diffusion model on a custom dataset, leveraging pre-trained diffusion models provided by the Hugging Face diffusers library.\\nâ€¢\\tConstructed the pipeline of the Stable Diffusion model and experimented with various models and schedulers, resulting in the construction of an efficient diffusion system capable of both inference and training.\",\n",
       "   'start_date': None,\n",
       "   'end_date': None},\n",
       "  {'title': 'PKL - Data Analysis',\n",
       "   'description': 'â€¢ Designed and developed a dynamic web application utilizing Servlet and JSP technologies, to interact with data and visualize it.\\nâ€¢ Implemented various normalization techniques to enhance data quality and defined relational schema ensuring data consistency.\\nâ€¢ Formulated analytical SQL queries, based on match and player-specific metrics to unveil patterns impacting match outcomes.\\nâ€¢ Leveraged tools such as Gradle and Docker to streamline development and deployment processes, enhancing project maintainability.',\n",
       "   'start_date': None,\n",
       "   'end_date': None},\n",
       "  {'title': 'Anime Recommender System',\n",
       "   'description': 'â€¢ Developed a recommendation engine using collaborative filtering techniques, such as item-item collaborative filtering and user-user collaborative filtering, to recommend anime to users based on their viewing history and preferences\\nâ€¢ Cleaned and Preprocessed the Anime Data and User rating Data to analyze and visualize it to get some interesting insights.\\nâ€¢ Recommended movies to the users based on the similarity score and predicted rating of new Anime for exiting users.',\n",
       "   'start_date': None,\n",
       "   'end_date': None},\n",
       "  {'title': 'Resume - Name Entity Recognition (NER) System',\n",
       "   'description': 'â€¢\\tImplemented a cutting-edge NER system for a Resume dataset, utilizing different model architectures, including LSTM (a recurrent neural network architecture), Transformers architecture, and Transformer Models such as BERT and DistilBERT.\\nâ€¢\\tPerformed data cleaning and pre-processing tasks such as tokenization, normalization, and encoding, and standardizing data formats to ensure high-quality input for the NER system for training and inference.\\nâ€¢\\tExperimented with different hyperparameters, model architectures, and tokenizers to optimize the performance of the NER system.\\nâ€¢\\tFine-tuned the DistilBERT model and achieve an overall improvement of 20% in performance compared to the baseline.',\n",
       "   'start_date': None,\n",
       "   'end_date': None},\n",
       "  {'title': 'Trigger Word Detection',\n",
       "   'description': 'â€¢ Constructed a speech dataset and developed a trigger word detection model to identify specific keywords in real-time audio streams.\\nâ€¢ Synthesized training data by combining recordings of positive and negative words with background noise in diverse environments.\\nâ€¢ Computed spectrogram of the raw audio file to help sequence model to easily detect trigger words.\\nâ€¢ Implemented a deep learning model, incorporating 1-D convolution layers, GRU layers, and dense layers in the architecture.',\n",
       "   'start_date': None,\n",
       "   'end_date': None},\n",
       "  {'title': 'The Harry Potter Network Graph',\n",
       "   'description': 'â€¢ Created and analyzed the network graph to extract the relationship between different characters of the Harry Potter Series\\nâ€¢ Scraped the names of all the characters along with the series name of the Harry Potter Series from the Wiki website.\\nâ€¢ Recognized the names of the characters in textual data of the books to establish relationships between the characters using spaCy.\\nâ€¢ Measured the centrality score for each character and detected communities within the network graph and visualized the network graph.',\n",
       "   'start_date': None,\n",
       "   'end_date': None},\n",
       "  {'title': 'Social Distancing Violation Detection',\n",
       "   'description': \"â€¢ Developed a model to analyze and calculate the physical distance among people to detect social distancing violations in real-time video footage in public places using the principles of object detection and Computer Vision.\\nâ€¢ Implemented an object detection algorithm, YOLO, to detect and track individuals' positions and movements within the video frames.\\nâ€¢ Implemented image transformation techniques to calculate the physical distance among people using a top-down view, enabling accurate and efficient detection of social distancing violations.\\nâ€¢ Designed and developed a web application displaying past recordings of violations, providing summary statistics of the number and types of violations made during a specific time interval, enabling easy analysis and visualization of the data.\\nâ€¢ Integrated the model and web application to enable real-time monitoring and analysis of social distancing violations in public places.\",\n",
       "   'start_date': None,\n",
       "   'end_date': None},\n",
       "  {'title': 'AssignBank â€“ Academic Centralization',\n",
       "   'description': 'â€¢ Designed and developed an end-to-end web application using HTML, CSS, JavaScript, and Node.js to centralize academic work and facilitate interaction between students and professors, which was used my more than 10K Students.\\nâ€¢ Created various features, including online registration, assignment creation and submission, video uploading, and performance grading for students.\\nâ€¢ Provided analytical charts on the faculty portal to get insights about performance of students in various examinations and deliverables.\\nâ€¢ Utilized Node.js as the backend technology and developed the application using the MVC framework to structure the codebase and ensure\\nseparation of concerns.\\nâ€¢ Implemented REST APIs to enable communication between the client-side and server-side components of the application.',\n",
       "   'start_date': None,\n",
       "   'end_date': None}]}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_linkedin_profile_data(\"https://www.linkedin.com/in/vatsal-thakkar-880320161/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AssetLink",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
